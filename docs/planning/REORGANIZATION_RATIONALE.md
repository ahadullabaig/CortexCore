# Development Roadmap Reorganization - Rationale

**Date**: November 9, 2025
**Decision**: Strategic pivot from linear progression to "Real Data First" approach

---

## Executive Summary

We are **reorganizing the development roadmap** to prioritize MIT-BIH real-world data validation (Phase 8) BEFORE synthetic data optimizations (Phase 3-7). This saves 16-21 days and reduces risk of over-fitting to synthetic data that doesn't represent clinical reality.

**Old Sequence**: Phase 1 â†’ 2 â†’ 3 â†’ 4 â†’ 5 â†’ 6 â†’ 7 â†’ 8 (36+ days to real data)
**New Sequence**: Phase 1 â†’ 2 â†’ 8 â†’ Decision â†’ 9-12 (15 days to real data)

---

## Why We're Reorganizing

### 1. We Hit Synthetic Data Ceiling

**Evidence from Tier 1 Optimization**:
- Baseline (threshold=0.5): 99.6% sens / 68.2% spec (extreme bias)
- After fixes (threshold=0.577): 90.6% sens / 89.0% spec (balanced)
- **ROC analysis proves**: NO threshold achieves both â‰¥95% sens AND â‰¥90% spec

**Conclusion**: Model has learned all it can from synthetic data. Further optimization yields <1% gains for 5-7 days work.

### 2. Synthetic â‰  Real Patient Data

**Synthetic Data Characteristics**:
- Generated by NeuroKit2 with fixed parameters
- Clean signals (SNR > 30dB)
- Limited variability (only 2 conditions: Normal 70BPM, Arrhythmia 120BPM)
- No patient-specific morphology
- No real-world artifacts (electrode motion, muscle noise, powerline interference)

**MIT-BIH Real Data Characteristics**:
- 48 actual patients, ages 23-89
- Noisy signals (SNR 15-25dB)
- High variability (medications, comorbidities, body types affect ECG)
- Patient-specific morphology (same arrhythmia looks different in different patients)
- Real artifacts (baseline wander, motion, poor electrode contact)

**Risk**: Model optimized on synthetic may achieve 95% but only 75% on real data. We need to know THIS EARLY.

### 3. Clinical Validation is Mandatory Anyway

**Regulatory/Clinical Requirements**:
- FDA approval: Requires validation on real patient data
- Academic publication: Journals require MIT-BIH or similar benchmark
- Hospital deployment: No physician trusts "95% on synthetic only"

**Timeline Implication**:
- Old plan: Reach MIT-BIH validation on Day 36
- New plan: Reach MIT-BIH validation on Day 15
- **Benefit**: If SNN approach fails on real data, we discover this 21 days earlier

### 4. We've Already Done Core Improvements

**What Original Plan Assumed**:
- SimpleSNN (2-layer, 320K params)
- Default loss function
- No threshold optimization
- Stochastic predictions (variance issues)

**What We Actually Have** (after Tier 1 work):
- âœ… DeepSNN (4-layer, 673K params) - deeper architecture (addresses Phase 4.1)
- âœ… FocalLoss + G-mean early stopping - class weighting (addresses Phase 3.2)
- âœ… ROC threshold optimization - optimal threshold (addresses Phase 2)
- âœ… Ensemble + seed consistency - deterministic predictions (addresses Phase 1)

**Implication**: We've already implemented equivalents of Phase 3 and 4 improvements. Doing them again on synthetic is redundant.

### 5. Evidence-Based Optimization is More Efficient

**Blind Optimization** (current plan):
```
Try Architecture A â†’ 5 days â†’ +1.2% on synthetic
Try Architecture B â†’ 7 days â†’ +0.8% on synthetic
Try Encoding C â†’ 5 days â†’ +1.5% on synthetic
Total: 17 days, +3.5% on WRONG target (synthetic data)
```

**Evidence-Based Optimization** (new plan):
```
MIT-BIH evaluation â†’ Error analysis reveals:
   60% errors on noisy segments â†’ Add noise robustness (3 days) â†’ +5% on real data
   25% errors on edge cases â†’ Add data augmentation (2 days) â†’ +2% on real data
   15% errors are rare arrhythmias â†’ Already handled by FocalLoss
Total: 5 days, +7% on RIGHT target (real data)
```

**Efficiency Gain**: 3.4x improvement (17 days â†’ 5 days for better results)

---

## Decision Logic

### Phase 8 (MIT-BIH) Results â†’ Next Action

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Run MIT-BIH Evaluation (7 test patients)   â”‚
â”‚ Measure: Sensitivity, Specificity, AUC     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           â”‚
    â–¼                           â–¼
â‰¥95% sens AND â‰¥90% spec    90-94% sens OR 85-89% spec    <90% sens OR <85% spec
    â”‚                           â”‚                              â”‚
    âœ… SUCCESS                  âš ï¸ CLOSE                       ğŸ”´ NEEDS WORK
    â”‚                           â”‚                              â”‚
    â”‚                           â”‚                              â”‚
    â–¼                           â–¼                              â–¼
Skip Phase 3-7           Apply Selective Fixes          Deep Error Analysis
    â”‚                           â”‚                              â”‚
    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                      â”‚
    â”‚                    â–¼             â–¼                       â–¼
    â”‚             Phase 3.2:    Phase 4.4:            Identify Top 3 Issues
    â”‚             Noise Aug     Attention                     â”‚
    â”‚                    â”‚             â”‚                       â”‚
    â”‚                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                      â”‚
    â”‚                           â”‚                              â”‚
    â”‚                           â–¼                              â–¼
    â”‚                    Retest MIT-BIH          Apply Comprehensive Phase 3-7
    â”‚                           â”‚                              â”‚
    â–¼                           â–¼                              â–¼
Phase 9: Multi-class    Phase 9: Multi-class         Phase 8 Retry
Phase 10: STDP          Phase 10: STDP                      â”‚
Phase 11: Production    Phase 11: Production                â”‚
Phase 12: Deployment    Phase 12: Deployment                â–¼
                                                      Re-evaluate Approach
                                                      (Consider Hybrid ANN-SNN)
```

---

## What We're NOT Skipping

**Phase 6 (STDP)**: Still required (problem statement mandates biological plausibility)
- **When**: After MIT-BIH validation succeeds
- **Why not skip**: Biological plausibility is core requirement, enables neuromorphic hardware deployment

**Phase 7 (Production)**: Still required (deployment needs optimized models)
- **When**: After MIT-BIH validation succeeds
- **Tasks**: Quantization, pruning, ONNX export
- **Why not skip**: Edge deployment requires optimized models

**Phase 3-7 (Conditional)**: May be needed based on MIT-BIH performance
- **When**: Only if MIT-BIH accuracy <95%/90%
- **Scope**: Selective (not all tasks), evidence-based (target specific issues)

---

## Timeline Comparison

### Original Plan (Linear Progression)

| Days | Phase | Activity | Outcome |
|------|-------|----------|---------|
| 1-2 | 1 | Variance reduction | âœ… COMPLETE |
| 3-4 | 2 | Evaluation | âœ… COMPLETE |
| 5-11 | 3 | Training improvements (synthetic) | 92% â†’ 94% |
| 12-18 | 4 | Architecture (synthetic) | 94% â†’ 95% |
| 19-23 | 5 | Encoding (synthetic) | 95% â†’ 96% |
| 24-30 | 6 | STDP (synthetic) | 96% â†’ 95% (hybrid) |
| 31-35 | 7 | Production | Quantized model |
| **36-40** | **8** | **MIT-BIH** | **??? (FIRST real data test!)** |

**Risk**: If MIT-BIH achieves only 78%, we spent 36 days optimizing wrong target.

### New Plan (Real Data First)

| Days | Phase | Activity | Outcome |
|------|-------|----------|---------|
| 1-2 | 1 | Variance reduction | âœ… COMPLETE |
| 3-10 | 2 | Evaluation + Tier 1 fixes | âœ… COMPLETE (90.6%/89.0%) |
| **11-15** | **8** | **MIT-BIH** | **â‰¥90% (validate approach)** |
| 16-20 | 9 | Multi-class OR selective fixes | 5-class detection |
| 21-27 | 10 | STDP | Biological plausibility |
| 28-30 | 11 | Production | Deployment-ready |
| 30+ | 12 | Clinical deployment | Hospital/wearable integration |

**Benefit**: Know if approach works by Day 15 instead of Day 36 (21 days saved).

---

## Risk Mitigation

### Risk: MIT-BIH Performance < 85%

**Probability**: Medium (20%)
**Impact**: High (requires major rework)

**Mitigations**:
1. **Transfer learning**: Load synthetic model weights (expect 5-8% boost)
2. **Ensemble prediction**: Already implemented (expect 2-3% boost)
3. **Class balancing**: FocalLoss + G-mean (expect 3-5% boost)
4. **Realistic expectation**: Literature shows SNNs achieve 86-89% on MIT-BIH
   - Our target: 90-92% (competitive, not state-of-the-art)
   - If we achieve 88-90%, that's SUCCESS for an SNN

**Backup Plan**: If <80%, combine MIT-BIH + PTB-XL for larger training set (30K samples vs 8K)

### Risk: Patient Variability Causes High Variance

**Problem**: Only 7 test patients â†’ metrics may be unstable

**Mitigation**:
- 5-fold cross-validation (train on 5 different patient splits)
- Report mean Â± std dev across folds
- Gives confidence intervals on performance

### Risk: Discover SNN Fundamental Limitation

**Problem**: SNNs inherently can't handle noisy medical signals

**Probability**: Low (10%) - literature shows SNNs work
**Impact**: Critical (project pivot required)

**Backup Plan**:
- Hybrid ANN-SNN: CNN encoder (learns features from raw signal) + SNN classifier
- Combines ANN accuracy with SNN energy efficiency
- Still demonstrates neuromorphic computing value

---

## Success Criteria for Reorganized Plan

### Phase 8 Completion (Day 15)

**Minimum Success** (proceed to Phase 9):
- âœ… MIT-BIH test accuracy â‰¥85%
- âœ… Sensitivity â‰¥85%, Specificity â‰¥80%
- âœ… All preprocessing pipeline documented
- âœ… Model performance comparable to SNN literature (86-89%)

**Target Success** (proceed directly to deployment):
- âœ… MIT-BIH test accuracy â‰¥90%
- âœ… Sensitivity â‰¥90%, Specificity â‰¥85%
- âœ… Error analysis identifies specific improvement areas
- âœ… Competitive with published SNN results

**Stretch Success** (skip optimization phases):
- âœ… MIT-BIH test accuracy â‰¥92%
- âœ… Sensitivity â‰¥95%, Specificity â‰¥90% (meets clinical targets)
- âœ… Matches or exceeds published SNN results
- âœ… Ready for multi-class expansion

### Overall Project Success (Day 30)

**Deliverables**:
1. âœ… Validated SNN model on MIT-BIH real data (â‰¥90% accuracy)
2. âœ… Multi-class arrhythmia detection (5 classes, â‰¥85% accuracy)
3. âœ… STDP hybrid implementation (biological plausibility demonstrated)
4. âœ… Quantized production model (<500KB, <50ms inference on Jetson)
5. âœ… Deployment demo (mobile app OR hospital integration)
6. âœ… Documentation for clinical validation and publication

**Scientific Contribution**:
- Demonstrates SNNs are viable for medical signal processing
- Shows 90%+ accuracy on real patient data (not just synthetic)
- Validates energy efficiency claims (60% reduction vs CNN)
- Provides reproducible benchmark for neuromorphic medical AI

---

## Implementation Plan for Phase 8 (Days 11-15)

### Day 11: Data Acquisition
- Download MIT-BIH from PhysioNet
- Implement preprocessing pipeline
- Generate patient-based splits
- **Deliverable**: `data/mitbih/{train,val,test}_ecg.pt`

### Day 12: Transfer Learning
- Load synthetic model checkpoint
- Implement layer freezing
- Start training (Epochs 1-30)
- **Deliverable**: Transfer learning in progress

### Day 13: Training Completion
- Complete training (Epochs 31-50)
- Early stopping based on G-mean
- **Deliverable**: Trained MIT-BIH model

### Day 14: Evaluation
- Comprehensive test set evaluation
- Clinical metrics, confusion matrix, ROC
- Error analysis
- **Deliverable**: `docs/MITBIH_RESULTS.md`

### Day 15: Decision Point
- Review results vs criteria
- Decide: Phase 9 (multi-class) OR selective fixes OR deep dive
- **Deliverable**: Next phase plan

---

## Conclusion

**The core insight**: We cannot claim success based on synthetic data alone. Real-world validation is mandatory for clinical deployment, academic publication, and regulatory approval.

**The strategic pivot**: Instead of spending 26 days optimizing synthetic data before validating on real data, we validate on real data FIRST (Day 15). This:
1. **Saves time**: 21 days earlier validation
2. **Reduces risk**: Discover showstoppers early
3. **Enables evidence-based optimization**: Fix real problems, not hypothetical ones
4. **Aligns with requirements**: Clinical validation is mandatory anyway

**The expected outcome**: By Day 15, we know if SNN approach is viable for medical AI. By Day 30, we have a validated, production-ready, clinically-tested arrhythmia detection system.

---

**Next Action**: Begin Phase 8, Task 8.1 (MIT-BIH data acquisition) immediately.

**Reference Documents**:
- Full reorganized roadmap: `docs/NEXT_STEPS_REORGANIZED.md`
- Original roadmap (for reference): `docs/NEXT_STEPS_DETAILED.md`
- Tier 1 results: `docs/TIER1_FINAL_RESULTS.md`
- Deployment decision: `docs/DEPLOYMENT_DECISION.md`
