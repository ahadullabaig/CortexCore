{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Quick Prototype - All-in-One Workspace\n",
    "\n",
    "**Purpose:** Rapid prototyping and experimentation for the entire team\n",
    "\n",
    "**Use this notebook to:**\n",
    "- Test ideas quickly\n",
    "- Experiment with different approaches\n",
    "- Share code snippets\n",
    "- Debug integration issues\n",
    "\n",
    "**Team:** All members\n",
    "**Phase:** Days 1-7 (MVP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch & SNN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "\n",
    "# Data generation\n",
    "import neurokit2 as nk\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Matplotlib config\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Section 1: Quick Data Generation Test\n",
    "\n",
    "**Owner:** CS3 / Data Engineer\n",
    "\n",
    "Generate a few synthetic ECG samples to verify neurokit2 works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a single ECG sample\n",
    "ecg_normal = nk.ecg_simulate(duration=10, sampling_rate=250, heart_rate=70)\n",
    "ecg_arrhythmia = nk.ecg_simulate(duration=10, sampling_rate=250, heart_rate=120)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 6))\n",
    "\n",
    "axes[0].plot(ecg_normal)\n",
    "axes[0].set_title('Normal ECG (70 bpm)')\n",
    "axes[0].set_xlabel('Sample')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "axes[1].plot(ecg_arrhythmia, color='red')\n",
    "axes[1].set_title('Arrhythmia ECG (120 bpm)')\n",
    "axes[1].set_xlabel('Sample')\n",
    "axes[1].set_ylabel('Amplitude')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Generated ECG with {len(ecg_normal)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Section 2: Spike Encoding Test\n",
    "\n",
    "**Owner:** CS2 / SNN Expert\n",
    "\n",
    "Convert continuous signal to spike trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple rate coding\n",
    "def rate_encode(signal, num_steps=100, gain=10):\n",
    "    \"\"\"Convert signal to spike train using rate coding\"\"\"\n",
    "    # Normalize signal to [0, 1]\n",
    "    signal_norm = (signal - signal.min()) / (signal.max() - signal.min())\n",
    "    \n",
    "    # Bin signal\n",
    "    bins = np.linspace(0, len(signal), num_steps+1, dtype=int)\n",
    "    rates = np.array([signal_norm[bins[i]:bins[i+1]].mean() for i in range(num_steps)])\n",
    "    \n",
    "    # Generate spikes based on rate\n",
    "    spikes = np.random.rand(num_steps) < (rates * gain)\n",
    "    \n",
    "    return spikes.astype(float)\n",
    "\n",
    "# Test encoding\n",
    "spike_train = rate_encode(ecg_normal, num_steps=100)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 6))\n",
    "\n",
    "# Original signal\n",
    "axes[0].plot(ecg_normal)\n",
    "axes[0].set_title('Original ECG Signal')\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "\n",
    "# Spike train\n",
    "spike_times = np.where(spike_train)[0]\n",
    "axes[1].eventplot(spike_times, colors='black')\n",
    "axes[1].set_title('Encoded Spike Train (Rate Coding)')\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Neuron')\n",
    "axes[1].set_ylim([0.5, 1.5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Encoded to {spike_train.sum():.0f} spikes ({spike_train.sum()/len(spike_train)*100:.1f}% active)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Section 3: Simple SNN Test\n",
    "\n",
    "**Owner:** CS2 / SNN Expert\n",
    "\n",
    "Create and test a basic snnTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple SNN with LIF neurons\n",
    "class SimpleSNN(nn.Module):\n",
    "    def __init__(self, input_size=100, hidden=64, output=2, beta=0.9):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden, output)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        \n",
    "        # Record spikes\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "        \n",
    "        # Process each timestep\n",
    "        for step in range(x.size(0)):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            \n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            \n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "        \n",
    "        return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
    "\n",
    "# Create model\n",
    "model = SimpleSNN().to(device)\n",
    "print(model)\n",
    "print(f\"\\n‚úÖ Model has {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "test_input = torch.randn(100, 1, 100).to(device)  # [time_steps, batch, features]\n",
    "spikes, membrane = model(test_input)\n",
    "\n",
    "print(f\"‚úÖ Forward pass successful!\")\n",
    "print(f\"   Output shape: {spikes.shape}\")\n",
    "print(f\"   Total spikes: {spikes.sum().item():.0f}\")\n",
    "print(f\"   Sparsity: {(1 - spikes.sum() / spikes.numel()) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Section 4: Visualization Tests\n",
    "\n",
    "**Owner:** CS4 / Deployment\n",
    "\n",
    "Test visualization components for the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive spike raster plot with Plotly\n",
    "def plot_spike_raster(spikes, title=\"Spike Raster Plot\"):\n",
    "    \"\"\"\n",
    "    Create interactive spike raster plot\n",
    "    spikes: [time_steps, neurons] tensor\n",
    "    \"\"\"\n",
    "    spikes_np = spikes.detach().cpu().numpy()\n",
    "    \n",
    "    # Find spike times and neuron indices\n",
    "    spike_times, neurons = np.where(spikes_np > 0)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=spike_times,\n",
    "        y=neurons,\n",
    "        mode='markers',\n",
    "        marker=dict(size=3, color='black'),\n",
    "        name='Spikes'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Time Step\",\n",
    "        yaxis_title=\"Neuron Index\",\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Plot output spikes from SNN\n",
    "fig = plot_spike_raster(spikes[:, 0, :], \"SNN Output Spike Pattern\")\n",
    "fig.show()\n",
    "\n",
    "print(\"‚úÖ Interactive visualization working!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Section 5: Integration Test\n",
    "\n",
    "**Owner:** CS1 / Team Lead\n",
    "\n",
    "End-to-end pipeline test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_full_pipeline():\n",
    "    \"\"\"Test complete data ‚Üí model ‚Üí prediction pipeline\"\"\"\n",
    "    print(\"Testing full pipeline...\\n\")\n",
    "    \n",
    "    # 1. Generate data\n",
    "    print(\"1Ô∏è‚É£ Generating ECG...\")\n",
    "    ecg = nk.ecg_simulate(duration=10, sampling_rate=250, heart_rate=70)\n",
    "    print(f\"   ‚úÖ Shape: {ecg.shape}\")\n",
    "    \n",
    "    # 2. Encode to spikes\n",
    "    print(\"\\n2Ô∏è‚É£ Encoding to spikes...\")\n",
    "    spikes = rate_encode(ecg, num_steps=100)\n",
    "    spikes_tensor = torch.FloatTensor(spikes).unsqueeze(1).unsqueeze(2).repeat(1, 1, 100).to(device)\n",
    "    print(f\"   ‚úÖ Shape: {spikes_tensor.shape}\")\n",
    "    \n",
    "    # 3. Model inference\n",
    "    print(\"\\n3Ô∏è‚É£ Running SNN inference...\")\n",
    "    with torch.no_grad():\n",
    "        output_spikes, _ = model(spikes_tensor)\n",
    "    print(f\"   ‚úÖ Output shape: {output_spikes.shape}\")\n",
    "    \n",
    "    # 4. Get prediction\n",
    "    print(\"\\n4Ô∏è‚É£ Making prediction...\")\n",
    "    spike_counts = output_spikes.sum(dim=0)  # Sum over time\n",
    "    prediction = spike_counts.argmax(dim=1)\n",
    "    confidence = torch.softmax(spike_counts, dim=1)\n",
    "    print(f\"   ‚úÖ Prediction: {prediction.item()} (confidence: {confidence.max().item():.2%})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"‚úÖ FULL PIPELINE WORKING!\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "test_full_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notes & TODO\n",
    "\n",
    "### What's Working:\n",
    "- ‚úÖ Data generation (neurokit2)\n",
    "- ‚úÖ Spike encoding (rate coding)\n",
    "- ‚úÖ Basic SNN model (snnTorch)\n",
    "- ‚úÖ Visualization (plotly)\n",
    "- ‚úÖ End-to-end pipeline\n",
    "\n",
    "### Next Steps:\n",
    "1. **CS3:** Implement better spike encoding (temporal/latency)\n",
    "2. **CS2:** Train model on real dataset\n",
    "3. **CS2:** Implement STDP learning\n",
    "4. **CS4:** Build Flask API around this\n",
    "5. **Bio:** Validate predictions make medical sense\n",
    "6. **CS1:** Refactor into src/ modules\n",
    "\n",
    "### Known Issues:\n",
    "- Model not trained yet (random predictions)\n",
    "- Simple rate encoding (try temporal encoding)\n",
    "- No data augmentation\n",
    "- No clinical validation\n",
    "\n",
    "### Team Communication:\n",
    "**Add your notes here for team members!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
